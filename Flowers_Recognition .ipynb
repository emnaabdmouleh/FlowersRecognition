{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "IR2cFm7UdgDJ",
        "-wBvnuW1dgDO",
        "drz8sPETdgDQ",
        "sWmjii1gdgDT",
        "X30dLzXZdgDX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR2cFm7UdgDJ"
      },
      "source": [
        "# Image Classification Using CNN\n",
        "By : Dhia Chelly&Emna Abd Mouleh\n",
        "\n",
        "________\n",
        "\n",
        "we'll build a CNN using Keras to use it classifying pictures in 3 different categories\n",
        "\n",
        "\n",
        "first to import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-6SA60TK1An"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE_G7jQ_uEA7"
      },
      "source": [
        "extraire les dossiers des images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzqXIAAkt2w"
      },
      "source": [
        "!unzip /DATABASE.zip   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP8kDKDz78M_"
      },
      "source": [
        "now to define the path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkO08pEAKAf7"
      },
      "source": [
        "#now to define the path\n",
        "trainpath ='/DATABASE/TRAIN/'\n",
        "testpath ='/DATABASE/VAL/'\n",
        "predpath= '/DATABASE/TEST/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wBvnuW1dgDO"
      },
      "source": [
        "# Open Folders\n",
        "\n",
        "now let's first check the Train folder to have a look to its content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni6PBAP2tlu6"
      },
      "source": [
        "for folder in  os.listdir(trainpath) : \n",
        "    files = gb.glob(pathname= str( trainpath  + folder + '/*.jpg'))\n",
        "    print(f'For training data , found {len(files)} in folder {folder}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggjfc5URdgDO"
      },
      "source": [
        "ok , how about the test folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OQ2zyH0dgDP"
      },
      "source": [
        "for folder in  os.listdir(testpath) : \n",
        "    files = gb.glob(pathname= str(testpath+ folder + '/*.jpg'))\n",
        "    print(f'For testing data , found {len(files)} in folder {folder}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fIu8NLP8QCv"
      },
      "source": [
        "ok , how about the test folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUte5s6OdgDQ"
      },
      "source": [
        "for folder in  os.listdir(predpath) : \n",
        "  files = gb.glob(pathname= str(predpath+ folder + '/*.jpg'))\n",
        "  print(f'For testing data , found {len(files)} in folder {folder}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drz8sPETdgDQ"
      },
      "source": [
        "_____\n",
        "\n",
        "# Checking Images\n",
        "\n",
        "now we need to heck the images sizes , to know ow they looks like\n",
        "\n",
        "since we have 5 categories , we first need to create a dictionary with their names & indices , also create a function to get the code back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTwwCdhKsrSY"
      },
      "source": [
        "code = {'dandelion':0,'rose':1,'sunflower':2}\n",
        "\n",
        "def getcode(n) : \n",
        "    for x , y in code.items() : \n",
        "        if n == y : \n",
        "            return x    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WdVa9PstFLx"
      },
      "source": [
        "now how about the images sizes in train folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdokvDKbtH9U"
      },
      "source": [
        "size = []\n",
        "for folder in  os.listdir(trainpath) : \n",
        "    files = gb.glob(pathname= str( trainpath + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = plt.imread(file)\n",
        "        size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIrhYxHQdgDR"
      },
      "source": [
        "______\n",
        "\n",
        "ok , min size : 240,215,3 , how about test images ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twFxUnGUdgDR"
      },
      "source": [
        "size = []\n",
        "for folder in  os.listdir(testpath) : \n",
        "    files = gb.glob(pathname= str( testpath + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = plt.imread(file)\n",
        "        size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgIgukMAdgDS"
      },
      "source": [
        " now to prediction images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BiGyL5odgDS"
      },
      "source": [
        "size = []\n",
        "for folder in  os.listdir(predpath) : \n",
        "    files = gb.glob(pathname= str( predpath + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = plt.imread(file)\n",
        "        size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWmjii1gdgDT"
      },
      "source": [
        "# Reading Images\n",
        "\n",
        "now it's time to read all images & convert it into arrays\n",
        "\n",
        "first we'll create a variable s , which refer to size , so we can change it easily \n",
        "\n",
        "let's use now size = 200 , so it will be suitable amount to contain accuracy without losing so much time in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYSIyseDdgDT"
      },
      "source": [
        "s = 175"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiVyoj56dgDT"
      },
      "source": [
        "now to read all pictues in 5 categories in training folder, ans use OpenCV to resize it , and not to forget to assign the y value , from the predefined function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1iuc_KkdgDT"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for folder in  os.listdir(trainpath) : \n",
        "    files = gb.glob(pathname= str( trainpath+ folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = cv2.imread(file)\n",
        "        image_array = cv2.resize(image , (s,s))\n",
        "        X_train.append(list(image_array))\n",
        "        y_train.append(code[folder])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGoxGH3zdgDU"
      },
      "source": [
        "great , now how many items in X_train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb5tc6_0dgDU"
      },
      "source": [
        "print(f'we have {len(X_train)} items in X_train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S78jhp6ddgDU"
      },
      "source": [
        "also we have have a look to random pictures in X_train , and to adjust their title using the y value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzLOaKKUdgDV"
      },
      "source": [
        "great , now to repeat same steps exactly in test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaAEXRrdgDV"
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "for folder in  os.listdir(testpath) : \n",
        "    files = gb.glob(pathname= str(testpath + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = cv2.imread(file)\n",
        "        image_array = cv2.resize(image , (s,s))\n",
        "        X_test.append(list(image_array))\n",
        "        y_test.append(code[folder])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTDSyzWEdgDV"
      },
      "source": [
        "print(f'we have {len(X_test)} items in X_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6OYvePIdgDW"
      },
      "source": [
        "also with Prediction data , without having title ofcourse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb_o7jUEdgDW"
      },
      "source": [
        "X_pred = []\n",
        "for folder in  os.listdir(testpath) : \n",
        "   files = gb.glob(pathname= str(predpath+ folder + '/*.jpg'))\n",
        "   for file in files: \n",
        "    image = cv2.imread(file)\n",
        "    image_array = cv2.resize(image , (s,s))\n",
        "    X_pred.append(list(image_array))       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdl8pmIvdgDW"
      },
      "source": [
        "print(f'we have {len(X_pred)} items in X_pred')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeEnmfZodgDS"
      },
      "source": [
        "ok ,  we can feel comfort in using all pictures in our model , after resizing it in a specific amount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X30dLzXZdgDX"
      },
      "source": [
        "________\n",
        "\n",
        "# Building The Model \n",
        "\n",
        "now we need to build the model to train our data\n",
        "\n",
        "first to convert the data into arrays using numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdS9AMc_dgDX"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_pred_array = np.array(X_pred)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(f'X_train shape  is {X_train.shape}')\n",
        "print(f'X_test shape  is {X_test.shape}')\n",
        "print(f'X_pred shape  is {X_pred_array.shape}')\n",
        "print(f'y_train shape  is {y_train.shape}')\n",
        "print(f'y_test shape  is {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qIZBEMqXdzT"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range = 20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.4, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCs8oBQvdgDX"
      },
      "source": [
        "now to build the CNN model by Keras , using Conv2D layers , MaxPooling & Denses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfRajDfBesP3"
      },
      "source": [
        "KerasModel = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(s,s,3)),\n",
        "        keras.layers.MaxPool2D(2,2, padding=\"same\"),\n",
        "        keras.layers.Dropout(rate=0.2) , \n",
        "        keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'), \n",
        "        keras.layers.MaxPool2D(2,2, padding=\"same\"),\n",
        "        keras.layers.Dropout(rate=0.2) , \n",
        "        keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu'), \n",
        "        keras.layers.MaxPool2D(2,2, padding=\"same\"),\n",
        "        keras.layers.Dropout(rate=0.2) , \n",
        "        keras.layers.Flatten() ,    \n",
        "        keras.layers.Dense(512,activation='relu') ,           \n",
        "        keras.layers.Dropout(rate=0.2) ,  \n",
        "        keras.layers.Dense(128,activation='relu') ,           \n",
        "        keras.layers.Dropout(rate=0.2) ,            \n",
        "        keras.layers.Dense(3,activation='softmax') ,    \n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZY6tyHsdgDY"
      },
      "source": [
        "now to compile the model , using adam optimizer , & sparse categorical crossentropy loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhFfVvYQdgDY"
      },
      "source": [
        "KerasModel.compile(optimizer ='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi_WmjDEdgDY"
      },
      "source": [
        "so how the model looks like ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3eVoDRJdgDY"
      },
      "source": [
        "print('Model Details are : ')\n",
        "print(KerasModel.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa3juEmQdgDY"
      },
      "source": [
        "now to train the model , lets use 20 epochs now\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuJNZUP9dgDZ"
      },
      "source": [
        "epochs = 20\n",
        "ThisModel = KerasModel.fit(X_train, y_train, epochs=epochs,batch_size=128,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBtr_2j8dgDZ"
      },
      "source": [
        "how is the final loss & accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAUvC52gJo99"
      },
      "source": [
        "ModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)\n",
        "\n",
        "print('Test Loss is {}'.format(ModelLoss))\n",
        "print('Test Accuracy is {}'.format(ModelAccuracy ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak3_-SuddgDa"
      },
      "source": [
        "** ok** , only **76**% accuracy & can be increased by tuning the hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrg2rBa_dgDb"
      },
      "source": [
        "y_pred = KerasModel.predict(X_test)\n",
        "\n",
        "print('Prediction Shape is {}'.format(y_pred.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8umUEoLdgDb"
      },
      "source": [
        "great\n",
        "\n",
        "now it's time to redict X Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpVAyo-TdgDb"
      },
      "source": [
        "y_result = KerasModel.predict(X_pred_array)\n",
        "\n",
        "print('Prediction Shape is {}'.format(y_result.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S95TGymqdgDc"
      },
      "source": [
        "and to show random redicted pictures & its predicting category\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2iXTAFtdgDc"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for  i in range( len(X_pred)) : \n",
        "    plt.subplot(6,5,i+1)\n",
        "    plt.imshow(X_pred[i])    \n",
        "    plt.axis('off')\n",
        "    plt.title(getcode(np.argmax(y_result[i])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}